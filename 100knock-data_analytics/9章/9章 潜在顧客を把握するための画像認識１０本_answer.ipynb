{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30317,"status":"ok","timestamp":1654454858468,"user":{"displayName":"下山輝昌","userId":"17333420985264756541"},"user_tz":-540},"id":"HesewxCRXG4H","outputId":"83ae946c-2a24-478b-d003-ae3afa88845d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Google Driveと接続を行います。これを行うことで、Driveにあるデータにアクセスできるようになります。\n","# 下記セルを実行すると、Googleアカウントのログインを求められますのでログインしてください。\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":530,"status":"ok","timestamp":1654454858994,"user":{"displayName":"下山輝昌","userId":"17333420985264756541"},"user_tz":-540},"id":"J_9P7DEhZWGH"},"outputs":[],"source":["# 作業フォルダへの移動を行います。\n","# 人によって作業場所がことなるので、その場合作業場所を変更してください。\n","import os \n","os.chdir('/content/drive/MyDrive/100knock-data_analytics/9章') #ここを変更。"]},{"cell_type":"markdown","metadata":{"id":"hLE1qg8_XG4J"},"source":["# 9章 潜在顧客を把握するための画像認識１０本\n","\n","ここでは、カメラから取得した映像を用いて画像認識を行い、  \n","必要な情報を取得するための流れを学ぶことで、  \n","画像認識をビジネス現場で応用するイメージをつかみます。"]},{"cell_type":"markdown","metadata":{"id":"oxFnvue4XG4L"},"source":["### ノック８１：画像データを読み込んでみよう"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":922,"output_embedded_package_id":"1kndKBIHosH6FVD7o-Op2y7CA6TXMsTrw"},"executionInfo":{"elapsed":19689,"status":"ok","timestamp":1654454880800,"user":{"displayName":"下山輝昌","userId":"17333420985264756541"},"user_tz":-540},"id":"yhYqDPexXG4L","outputId":"284a4476-d23e-449e-b8a2-eddd84c9e657"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","\n","img = cv2.imread(\"img/img01.jpg\")\n","height, width = img.shape[:2]\n","print(\"画像幅: \" + str(width))\n","print(\"画像高さ: \" + str(height))\n","\n","cv2_imshow(img)"]},{"cell_type":"markdown","metadata":{"id":"Pc7KWLOAXG4M"},"source":["### ノック８２：映像データを読み込んでみよう"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":477,"output_embedded_package_id":"1OUugg-2c8WT3B0XAeUE-4c4JZGP_WbVP"},"executionInfo":{"elapsed":86965,"status":"ok","timestamp":1654454967755,"user":{"displayName":"下山輝昌","userId":"17333420985264756541"},"user_tz":-540},"id":"eg0es8XAXG4M","outputId":"a7c48671-84ba-4b64-b0de-eaa29d14ce75"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","from IPython.display import HTML\n","\n","# 情報取得 #\n","cap = cv2.VideoCapture(\"mov/mov01.avi\")\n","width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n","height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","print(\"画像幅: \" + str(width))\n","print(\"画像高さ: \" + str(height))\n","print(\"総フレーム数: \" + str(count))\n","print(\"FPS: \" + str(fps))\n","\n","# 映像のフレーム画像化 #\n","num = 0\n","num_frame = 100\n","list_frame = []\n","while(cap.isOpened()):\n","    # 処理（フレームごとに切り出し）\n","    ret, frame = cap.read()\n","    # 出力（フレーム画像を書き出し）\n","    if ret:\n","        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        list_frame.append(frame_rgb)\n","        if cv2.waitKey(1) \u0026 0xFF == ord('q'):\n","          break\n","        if num\u003enum_frame:\n","          break\n","    num = num + 1\n","print(\"処理を完了しました\")\n","cap.release()\n","\n","# フレーム画像をアニメーションに変換 #\n","plt.figure()\n","patch = plt.imshow(list_frame[0])\n","plt.axis('off')\n","def animate(i):\n","    patch.set_data(list_frame[i])\n","anim = FuncAnimation(plt.gcf(), animate, frames=len(list_frame), interval=1000/30.0)\n","plt.close()\n","\n","# アニメーションを表示 #\n","HTML(anim.to_jshtml())"]},{"cell_type":"markdown","metadata":{"id":"WG3oXnHAXG4N"},"source":["### ノック８３：映像を画像に分割し、保存してみよう"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1jZT4QNXG4N"},"outputs":[],"source":["cap = cv2.VideoCapture(\"mov/mov01.avi\")\n","num = 0\n","count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","while(cap.isOpened()):\n","    ret, frame = cap.read()\n","    if ret:\n","        filepath = \"snapshot/snapshot_\" + str(num) + \".jpg\"\n","        cv2.imwrite(filepath,frame)\n","    num = num + 1\n","    if num\u003e=count:\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"lCe49JcPXG4O"},"source":["### ノック８４：画像内のどこに人がいるのかを検出してみよう"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1G4Cju0AvV_WzeLc5wEWUCaSqjtSzKbtd"},"id":"EtEBOL1kXG4O","outputId":"6e7da48f-6c94-4e1f-9e75-9c6659577e5b"},"outputs":[],"source":["# 準備 #\n","hog = cv2.HOGDescriptor()\n","hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n","hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n","\n","# 検出 #\n","img = cv2.imread(\"img/img01.jpg\")\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","human, r = hog.detectMultiScale(gray, **hogParams)\n","if (len(human)\u003e0):\n","    for (x, y, w, h) in human:\n","        cv2.rectangle(img, (x, y), (x + w, y + h), (255,255,255), 3)\n","cv2_imshow(img)\n","cv2.imwrite(\"temp.jpg\",img)"]},{"cell_type":"markdown","metadata":{"id":"WLZBD3DzXG4P"},"source":["### ノック８５：画像内の人の顔を検出してみよう"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"19R6b2doW4bJBeNVTJXR89RXNPLW0bW4X"},"id":"NPPf_QYqXG4P","outputId":"d9a9c5b8-6265-4ef9-ab3c-6b67ea4095fa"},"outputs":[],"source":["# 準備\n","cascade_file = \"haarcascade_frontalface_alt.xml\"\n","cascade = cv2.CascadeClassifier(cascade_file)\n","\n","# 検出\n","img = cv2.imread(\"img/img02.jpg\")\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","face_list = cascade.detectMultiScale(gray, minSize=(50, 50))\n","\n","# 検出した顔に印を付ける\n","for (x, y, w, h) in face_list:\n","    color = (0, 0, 225)\n","    pen_w = 3\n","    cv2.rectangle(img, (x, y), (x+w, y+h), color, thickness = pen_w)\n","\n","cv2_imshow(img)\n","cv2.imwrite(\"temp.jpg\",img)"]},{"cell_type":"markdown","metadata":{"id":"x4QBRKZbXG4P"},"source":["### ノック８６：画像内の人がどこに顔を向けているのかを検出してみよう"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1bLVuogKqay4NEZQEOHXxOYY_B3IRdXXP"},"id":"mqxruDQUXG4P","outputId":"12b06b74-7f2c-49ee-b520-43c89904ba04"},"outputs":[],"source":["import dlib\n","import math\n","\n","# 準備 #\n","predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n","detector = dlib.get_frontal_face_detector()\n","\n","# 検出 #\n","img = cv2.imread(\"img/img02.jpg\")\n","dets = detector(img, 1)\n","\n","for k, d in enumerate(dets):\n","    shape = predictor(img, d)\n","\n","    # 顔領域の表示\n","    color_f = (0, 0, 225)\n","    color_l_out = (255, 0, 0)\n","    color_l_in = (0, 255, 0)\n","    line_w = 3\n","    circle_r = 3\n","    fontType = cv2.FONT_HERSHEY_SIMPLEX\n","    fontSize = 1\n","    cv2.rectangle(img, (d.left(), d.top()), (d.right(), d.bottom()), color_f, line_w)\n","    cv2.putText(img, str(k), (d.left(), d.top()), fontType, fontSize, color_f, line_w)\n","\n","    # 重心を導出する箱を用意\n","    num_of_points_out = 17\n","    num_of_points_in = shape.num_parts - num_of_points_out\n","    gx_out = 0\n","    gy_out = 0\n","    gx_in = 0\n","    gy_in = 0\n","    for shape_point_count in range(shape.num_parts):\n","        shape_point = shape.part(shape_point_count)\n","        #print(\"顔器官No.{} 座標位置: ({},{})\".format(shape_point_count, shape_point.x, shape_point.y))\n","        #器官ごとに描画\n","        if shape_point_count\u003cnum_of_points_out:\n","            cv2.circle(img,(shape_point.x, shape_point.y),circle_r,color_l_out, line_w)\n","            gx_out = gx_out + shape_point.x/num_of_points_out\n","            gy_out = gy_out + shape_point.y/num_of_points_out\n","        else:\n","            cv2.circle(img,(shape_point.x, shape_point.y),circle_r,color_l_in, line_w)\n","            gx_in = gx_in + shape_point.x/num_of_points_in\n","            gy_in = gy_in + shape_point.y/num_of_points_in\n","\n","    # 重心位置を描画\n","    cv2.circle(img,(int(gx_out), int(gy_out)),circle_r,(0,0,255), line_w)\n","    cv2.circle(img,(int(gx_in), int(gy_in)),circle_r,(0,0,0), line_w)\n","\n","    # 顔の方位を計算\n","    theta = math.asin(2*(gx_in-gx_out)/(d.right()-d.left()))\n","    radian = theta*180/math.pi\n","    print(\"顔方位:{} (角度:{}度)\".format(theta,radian))\n","\n","    # 顔方位を表示\n","    if radian\u003c0:\n","        textPrefix = \"   left \"\n","    else:\n","        textPrefix = \"   right \"\n","    textShow = textPrefix + str(round(abs(radian),1)) + \" deg.\"\n","    cv2.putText(img, textShow, (d.left(), d.top()), fontType, fontSize, color_f, line_w)\n","\n","cv2_imshow(img)\n","cv2.imwrite(\"temp.jpg\",img)"]},{"cell_type":"markdown","metadata":{"id":"vg1LU6pbXG4Q"},"source":["### ノック８７：検出した情報を統合し、タイムラプスを作ってみよう"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oEbp5OxlXG4Q"},"outputs":[],"source":["print(\"タイムラプス生成を開始します\")\n","\n","# 映像取得 #\n","cap = cv2.VideoCapture(\"mov/mov01.avi\")\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# hog宣言 #\n","hog = cv2.HOGDescriptor()\n","hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n","hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n","\n","# タイムラプス作成 #\n","movie_name = \"timelapse.avi\"\n","fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n","video = cv2.VideoWriter(movie_name,fourcc, 30, (width,height))\n","\n","num = 0\n","while(cap.isOpened()):\n","    ret, frame = cap.read()\n","    if ret:\n","        if (num%10==0):\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            human, r = hog.detectMultiScale(gray, **hogParams)\n","            if (len(human)\u003e0):\n","                for (x, y, w, h) in human:\n","                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n","\n","            video.write(frame)\n","    else:\n","        break\n","    num = num + 1\n","video.release()\n","cap.release()\n","cv2.destroyAllWindows()\n","print(\"タイムラプス生成を終了しました\")"]},{"cell_type":"markdown","metadata":{"id":"QNluOJEeXG4Q"},"source":["### ノック８８：全体像をグラフにして可視化してみよう"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Af7iz_dsXG4R"},"outputs":[],"source":["import pandas as pd\n","\n","print(\"分析を開始します\")\n","# 映像取得 #\n","cap = cv2.VideoCapture(\"mov/mov01.avi\")\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","# hog宣言 #\n","hog = cv2.HOGDescriptor()\n","hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n","hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n","\n","num = 0\n","list_df = pd.DataFrame( columns=['time','people'] )\n","while(cap.isOpened()):\n","    ret, frame = cap.read()\n","    if ret:\n","        if (num%10==0):\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            human, r = hog.detectMultiScale(gray, **hogParams)\n","            if (len(human)\u003e0):\n","                for (x, y, w, h) in human:\n","                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n","            tmp_se = pd.Series( [num/fps,len(human) ], index=list_df.columns )\n","            list_df = list_df.append( tmp_se, ignore_index=True )       \n","            if cv2.waitKey(1) \u0026 0xFF == ord('q'):\n","                break\n","    else:\n","        break\n","    num = num + 1\n","cap.release()\n","cv2.destroyAllWindows()\n","print(\"分析を終了しました\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nihjXGQXG4R"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(list_df[\"time\"], list_df[\"people\"])\n","plt.xlabel('time(sec.)')\n","plt.ylabel('population')\n","plt.ylim(0,15)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZouVzSOkXG4R"},"source":["### ノック８９：人通りの変化をグラフで確認しよう"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6OTpw22bXG4R"},"outputs":[],"source":["print(\"分析を開始します\")\n","# 映像取得 #\n","cap = cv2.VideoCapture(\"mov/mov02.avi\")\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","# hog宣言 #\n","hog = cv2.HOGDescriptor()\n","hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n","hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n","\n","num = 0\n","list_df2 = pd.DataFrame( columns=['time','people'] )\n","while(cap.isOpened()):\n","    ret, frame = cap.read()\n","    if ret:\n","        if (num%10==0):\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            human, r = hog.detectMultiScale(gray, **hogParams)\n","            if (len(human)\u003e0):\n","                for (x, y, w, h) in human:\n","                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n","            tmp_se = pd.Series( [num/fps,len(human) ], index=list_df.columns )\n","            list_df2 = list_df2.append( tmp_se, ignore_index=True )       \n","            if cv2.waitKey(1) \u0026 0xFF == ord('q'):\n","                break\n","    else:\n","        break\n","    num = num + 1\n","cap.release()\n","cv2.destroyAllWindows()\n","print(\"分析を終了しました\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1sEMdqsXG4S"},"outputs":[],"source":["plt.plot(list_df2[\"time\"], list_df2[\"people\"])\n","plt.xlabel('time(sec.)')\n","plt.ylabel('population')\n","plt.ylim(0,15)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ddZRehRtXG4S"},"source":["### ノック９０：移動平均を計算することでノイズの影響を除去しよう"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5hr-IGkXG4S"},"outputs":[],"source":["import numpy as np\n","def moving_average(x, y):\n","    y_conv = np.convolve(y, np.ones(5)/float(5), mode='valid')\n","    x_dat = np.linspace(np.min(x), np.max(x), np.size(y_conv))\n","    return x_dat, y_conv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TONfKDPqXG4S"},"outputs":[],"source":["plt.plot(list_df[\"time\"], list_df[\"people\"], label=\"raw\")\n","ma_x, ma_y = moving_average(list_df[\"time\"], list_df[\"people\"])\n","plt.plot(ma_x,ma_y, label=\"average\")\n","plt.xlabel('time(sec.)')\n","plt.ylabel('population')\n","plt.ylim(0,15)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKtw0-HBXG4S"},"outputs":[],"source":["plt.plot(list_df2[\"time\"], list_df2[\"people\"], label=\"raw\")\n","ma_x2, ma_y2 = moving_average(list_df2[\"time\"], list_df2[\"people\"])\n","plt.plot(ma_x2,ma_y2, label=\"average\")\n","plt.xlabel('time(sec.)')\n","plt.ylabel('population')\n","plt.ylim(0,15)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JtVXbA_dXG4S"},"outputs":[],"source":["plt.plot(ma_x,ma_y, label=\"1st\")\n","plt.plot(ma_x2,ma_y2, label=\"2nd\")\n","plt.xlabel('time(sec.)')\n","plt.ylabel('population')\n","plt.ylim(0,15)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_IREv5zd1_D"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"9章 潜在顧客を把握するための画像認識１０本_answer.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}